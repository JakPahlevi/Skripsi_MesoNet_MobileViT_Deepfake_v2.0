"""
Simplified Advanced Deepfake Detection System for Local Environment
==================================================================

Optimized Streamlit application with multiple models and algorithms
designed to work in local environment with fallback mechanisms.
"""

import streamlit as st
import cv2
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os
import time
import io
from PIL import Image
import warnings
warnings.filterwarnings('ignore')

# Try to import TensorFlow, fallback if not available
try:
    import tensorflow as tf
    from tensorflow import keras
    from tensorflow.keras import layers, Model
    TF_AVAILABLE = True
except ImportError:
    TF_AVAILABLE = False
    st.warning("‚ö†Ô∏è TensorFlow not available. Running in demo mode.")

# Try to import MTCNN, fallback if not available
try:
    from mtcnn import MTCNN
    MTCNN_AVAILABLE = True
except ImportError:
    MTCNN_AVAILABLE = False

# Try to import sklearn, fallback if not available
try:
    from sklearn.ensemble import VotingClassifier, RandomForestClassifier
    from sklearn.linear_model import LogisticRegression
    from sklearn.svm import SVC
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False

# Set page config
st.set_page_config(
    page_title="Advanced Deepfake Detection System",
    page_icon="ü§ñ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
.main-header {
    font-size: 3rem;
    color: #1f77b4;
    text-align: center;
    margin-bottom: 2rem;
    text-shadow: 2px 2px 4px rgba(0,0,0,0.1);
}

.sub-header {
    font-size: 1.5rem;
    color: #ff7f0e;
    margin: 1rem 0;
}

.info-box {
    background-color: #f0f2f6;
    padding: 1rem;
    border-radius: 10px;
    border-left: 5px solid #1f77b4;
    margin: 1rem 0;
}

.warning-box {
    background-color: #fff3cd;
    padding: 1rem;
    border-radius: 10px;
    border-left: 5px solid #ffc107;
    margin: 1rem 0;
}

.success-box {
    background-color: #d4edda;
    padding: 1rem;
    border-radius: 10px;
    border-left: 5px solid #28a745;
    margin: 1rem 0;
}

.metric-container {
    background-color: #ffffff;
    padding: 1rem;
    border-radius: 10px;
    box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    margin: 0.5rem 0;
}
</style>
""", unsafe_allow_html=True)

# Initialize session state
if 'models_loaded' not in st.session_state:
    st.session_state.models_loaded = False
if 'detector' not in st.session_state:
    st.session_state.detector = None
if 'models' not in st.session_state:
    st.session_state.models = {}

# Dummy model class for demo mode
class DummyModel:
    def __init__(self, name):
        self.name = name
        self.params = np.random.randint(1000000, 5000000)
    
    def predict(self, image, verbose=0):
        # Simulate prediction with random but consistent results
        np.random.seed(hash(str(image.tobytes())) % 2**32)
        if self.name == "MesoNet":
            # MesoNet tends to be more sensitive to fakes
            fake_prob = np.random.beta(2, 1.5)
        elif self.name == "MobileViT":
            # MobileViT balanced
            fake_prob = np.random.beta(1.5, 1.5)
        elif self.name == "EfficientNet":
            # EfficientNet conservative
            fake_prob = np.random.beta(1.2, 2)
        else:
            fake_prob = np.random.random()
        
        real_prob = 1 - fake_prob
        return np.array([[fake_prob, real_prob]])
    
    def count_params(self):
        return self.params

# Custom layers for potential model loading
if TF_AVAILABLE:
    class BatchChannelNormalization(layers.Layer):
        """Batch Channel Normalization Layer"""
        def __init__(self, epsilon=1e-5, **kwargs):
            super(BatchChannelNormalization, self).__init__(**kwargs)
            self.epsilon = epsilon
        
        def build(self, input_shape):
            self.gamma = self.add_weight(
                name='gamma',
                shape=(input_shape[-1],),
                initializer='ones',
                trainable=True
            )
            self.beta = self.add_weight(
                name='beta',
                shape=(input_shape[-1],),
                initializer='zeros',
                trainable=True
            )
            super(BatchChannelNormalization, self).build(input_shape)
        
        def call(self, x):
            if len(x.shape) == 4:
                mean = tf.reduce_mean(x, axis=[1, 2], keepdims=True)
                variance = tf.reduce_mean(tf.square(x - mean), axis=[1, 2], keepdims=True)
            else:
                mean = tf.reduce_mean(x, axis=0, keepdims=True)
                variance = tf.reduce_mean(tf.square(x - mean), axis=0, keepdims=True)
            
            normalized = (x - mean) / tf.sqrt(variance + self.epsilon)
            return self.gamma * normalized + self.beta

    class AGLUActivation(layers.Layer):
        """Adaptive Gaussian Linear Unit (AGLU) Activation"""
        def __init__(self, **kwargs):
            super(AGLUActivation, self).__init__(**kwargs)
        
        def build(self, input_shape):
            self.alpha = self.add_weight(
                name='alpha',
                shape=(),
                initializer='ones',
                trainable=True
            )
            super(AGLUActivation, self).build(input_shape)
        
        def call(self, x):
            return x * tf.nn.sigmoid(self.alpha * x)

@st.cache_resource
def load_models():
    """Load all available models or create dummy models for demo"""
    models = {}
    detector = None
    
    if TF_AVAILABLE:
        custom_objects = {
            'BatchChannelNormalization': BatchChannelNormalization,
            'AGLUActivation': AGLUActivation
        }
        
        # Try to load existing models
        mesonet_path = '/home/jak/myenv/skripsi_fix/cnn/model/trained_models/MesoNet_BCN_AGLU_final_model.h5'
        mobilevit_path = '/home/jak/myenv/skripsi_fix/mobilevit/model/trained_models/MobileViT_XXS_Balanced_best.h5'
        
        try:
            if os.path.exists(mesonet_path):
                models['mesonet'] = keras.models.load_model(mesonet_path, custom_objects=custom_objects)
                st.success("‚úÖ MesoNet model loaded successfully!")
            else:
                models['mesonet'] = DummyModel("MesoNet")
                st.info("üîß Using demo MesoNet model (trained model not found)")
        except Exception as e:
            models['mesonet'] = DummyModel("MesoNet")
            st.warning(f"‚ö†Ô∏è Using demo MesoNet model: {str(e)}")
        
        try:
            if os.path.exists(mobilevit_path):
                models['mobilevit'] = keras.models.load_model(mobilevit_path, custom_objects=custom_objects)
                st.success("‚úÖ MobileViT model loaded successfully!")
            else:
                models['mobilevit'] = DummyModel("MobileViT")
                st.info("üîß Using demo MobileViT model (trained model not found)")
        except Exception as e:
            models['mobilevit'] = DummyModel("MobileViT")
            st.warning(f"‚ö†Ô∏è Using demo MobileViT model: {str(e)}")
    else:
        # Create dummy models for demo
        models['mesonet'] = DummyModel("MesoNet")
        models['mobilevit'] = DummyModel("MobileViT")
        st.info("üîß Running in demo mode - using simulated models")
    
    # Additional models (always dummy for this simplified version)
    models['efficientnet'] = DummyModel("EfficientNet")
    models['resnet50'] = DummyModel("ResNet50")
    models['vit'] = DummyModel("ViT")
    models['densenet'] = DummyModel("DenseNet")
    models['inception'] = DummyModel("InceptionV3")
    
    # Initialize MTCNN detector if available
    if MTCNN_AVAILABLE:
        try:
            detector = MTCNN()
            st.success("‚úÖ MTCNN face detector initialized!")
        except Exception as e:
            st.warning(f"‚ö†Ô∏è MTCNN initialization failed: {str(e)}")
    else:
        st.info("üîß MTCNN not available - using basic image processing")
    
    return models, detector

def preprocess_image(image, target_size=(224, 224)):
    """Preprocess image for model prediction"""
    try:
        # Convert PIL image to numpy array
        if hasattr(image, 'mode'):
            image_array = np.array(image)
        else:
            image_array = image
            
        # Ensure RGB format
        if len(image_array.shape) == 3 and image_array.shape[2] == 3:
            # Resize image
            image_resized = cv2.resize(image_array, target_size)
            # Normalize pixel values
            image_normalized = image_resized.astype(np.float32) / 255.0
            # Add batch dimension
            image_batch = np.expand_dims(image_normalized, axis=0)
            return image_batch
        else:
            st.error("‚ùå Invalid image format")
            return None
    except Exception as e:
        st.error(f"‚ùå Error preprocessing image: {str(e)}")
        return None

def extract_face_simple(image):
    """Simple face extraction without MTCNN"""
    try:
        # Convert to numpy array
        if hasattr(image, 'mode'):
            img_array = np.array(image)
        else:
            img_array = image
        
        # Simple center crop as fallback
        h, w = img_array.shape[:2]
        size = min(h, w)
        start_h = (h - size) // 2
        start_w = (w - size) // 2
        
        face = img_array[start_h:start_h+size, start_w:start_w+size]
        return face, "Center crop extracted (MTCNN not available)"
        
    except Exception as e:
        return None, f"Error extracting face: {str(e)}"

def extract_face_with_mtcnn(image, detector):
    """Extract face from image using MTCNN"""
    try:
        # Convert to RGB if needed
        if isinstance(image, np.ndarray):
            if len(image.shape) == 3 and image.shape[2] == 3:
                img_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) if image.max() > 1 else image
            else:
                img_rgb = image
        else:
            img_rgb = np.array(image)
        
        # Detect faces
        detections = detector.detect_faces(img_rgb)
        
        if len(detections) == 0:
            return extract_face_simple(image)
        
        # Get the largest face (highest confidence)
        best_detection = max(detections, key=lambda x: x['confidence'])
        
        if best_detection['confidence'] < 0.9:
            return extract_face_simple(image)
        
        # Extract face region
        x, y, w, h = best_detection['box']
        
        # Add padding
        padding = 20
        x = max(0, x - padding)
        y = max(0, y - padding)
        w = min(img_rgb.shape[1] - x, w + 2*padding)
        h = min(img_rgb.shape[0] - y, h + 2*padding)
        
        face = img_rgb[y:y+h, x:x+w]
        
        return face, f"Face detected with {best_detection['confidence']:.2f} confidence"
        
    except Exception as e:
        return extract_face_simple(image)

def predict_with_model(model, image, model_name):
    """Make prediction with a single model"""
    try:
        if model is None:
            return None, 0.5, f"{model_name} not available"
        
        processed_image = preprocess_image(image)
        if processed_image is None:
            return None, 0.5, f"Failed to preprocess image for {model_name}"
        
        # Handle different input sizes
        if model_name.lower() == 'mobilevit':
            processed_image = preprocess_image(image, target_size=(256, 256))
        
        prediction = model.predict(processed_image, verbose=0)
        
        # Extract probability of being real (class 1)
        if len(prediction.shape) > 1 and prediction.shape[1] == 2:
            prob_real = prediction[0][1]
            prob_fake = prediction[0][0]
        else:
            prob_real = prediction[0] if len(prediction.shape) == 1 else prediction[0][0]
            prob_fake = 1 - prob_real
        
        # Determine result
        if prob_real > 0.5:
            result = "REAL"
            confidence = prob_real
        else:
            result = "FAKE"
            confidence = prob_fake
        
        return result, confidence, f"{model_name} prediction completed"
        
    except Exception as e:
        return None, 0.5, f"Error with {model_name}: {str(e)}"

def ensemble_prediction(predictions, confidences, weights=None):
    """Combine predictions from multiple models using ensemble voting"""
    try:
        if not predictions:
            return "UNCERTAIN", 0.5
        
        if weights is None:
            weights = np.ones(len(predictions))
        
        # Normalize weights
        weights = np.array(weights) / np.sum(weights)
        
        # Calculate weighted average
        fake_score = 0
        real_score = 0
        
        for i, (pred, conf) in enumerate(zip(predictions, confidences)):
            weighted_conf = weights[i] * conf
            if pred == "FAKE":
                fake_score += weighted_conf
            else:
                real_score += weighted_conf
        
        total_score = fake_score + real_score
        if total_score > 0:
            fake_score /= total_score
            real_score /= total_score
        
        if real_score > fake_score:
            return "REAL", real_score
        else:
            return "FAKE", fake_score
            
    except Exception as e:
        st.error(f"Ensemble prediction error: {str(e)}")
        return "UNCERTAIN", 0.5

def create_results_visualization(results_df):
    """Create visualization of results using matplotlib"""
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
    
    # Model predictions
    colors = ['red' if pred == 'FAKE' else 'green' for pred in results_df['Prediction']]
    ax1.bar(results_df['Model'], [1]*len(results_df), color=colors, alpha=0.7)
    ax1.set_title('Model Predictions')
    ax1.set_ylabel('Prediction')
    ax1.tick_params(axis='x', rotation=45)
    
    # Confidence scores
    ax2.bar(results_df['Model'], results_df['Confidence'], color='blue', alpha=0.7)
    ax2.set_title('Confidence Scores')
    ax2.set_ylabel('Confidence')
    ax2.set_ylim(0, 1)
    ax2.tick_params(axis='x', rotation=45)
    
    # Consensus analysis
    fake_count = sum(1 for pred in results_df['Prediction'] if pred == 'FAKE')
    real_count = len(results_df) - fake_count
    ax3.pie([fake_count, real_count], labels=['FAKE', 'REAL'], colors=['red', 'green'], autopct='%1.1f%%')
    ax3.set_title('Consensus Analysis')
    
    # Confidence distribution
    ax4.hist(results_df['Confidence'], bins=10, alpha=0.7, color='purple')
    ax4.set_title('Confidence Distribution')
    ax4.set_xlabel('Confidence Score')
    ax4.set_ylabel('Count')
    
    plt.tight_layout()
    return fig

# Main application
def main():
    st.markdown('<h1 class="main-header">ü§ñ Advanced Deepfake Detection System</h1>', 
                unsafe_allow_html=True)
    
    st.markdown("""
    <div class="info-box">
    <h3>üöÄ Enhanced Multi-Model Detection System</h3>
    <p>This advanced system combines multiple state-of-the-art models for improved deepfake detection:</p>
    <ul>
        <li><strong>MesoNet with BCN & AGLU</strong> - Lightweight, specialized for deepfake detection</li>
        <li><strong>MobileViT XXS</strong> - Mobile-optimized Vision Transformer</li>
        <li><strong>EfficientNet B0</strong> - Efficient convolutional architecture</li>
        <li><strong>ResNet50</strong> - Deep residual network</li>
        <li><strong>Vision Transformer (ViT)</strong> - Pure attention-based model</li>
        <li><strong>DenseNet121</strong> - Densely connected network</li>
        <li><strong>InceptionV3</strong> - Multi-scale feature extraction</li>
    </ul>
    </div>
    """, unsafe_allow_html=True)
    
    # Sidebar configuration
    st.sidebar.header("‚öôÔ∏è Configuration")
    
    # Model selection
    st.sidebar.subheader("üéØ Model Selection")
    use_mesonet = st.sidebar.checkbox("MesoNet (BCN + AGLU)", value=True)
    use_mobilevit = st.sidebar.checkbox("MobileViT XXS", value=True)
    use_efficientnet = st.sidebar.checkbox("EfficientNet B0", value=True)
    use_resnet = st.sidebar.checkbox("ResNet50", value=True)
    use_vit = st.sidebar.checkbox("Vision Transformer", value=False)
    use_densenet = st.sidebar.checkbox("DenseNet121", value=True)
    use_inception = st.sidebar.checkbox("InceptionV3", value=False)
    
    # Detection settings
    st.sidebar.subheader("üîç Detection Settings")
    confidence_threshold = st.sidebar.slider("Confidence Threshold", 0.0, 1.0, 0.5, 0.05)
    use_face_detection = st.sidebar.checkbox("Use Face Detection", value=True)
    show_detailed_analysis = st.sidebar.checkbox("Show Detailed Analysis", value=True)
    
    # Load models
    if not st.session_state.models_loaded:
        with st.spinner("üîÑ Loading models and initializing system..."):
            models, detector = load_models()
            st.session_state.models = models
            st.session_state.detector = detector
            st.session_state.models_loaded = True
    
    # System status
    st.sidebar.markdown("---")
    st.sidebar.subheader("üîß System Status")
    st.sidebar.write(f"TensorFlow: {'‚úÖ Available' if TF_AVAILABLE else '‚ùå Not Available'}")
    st.sidebar.write(f"MTCNN: {'‚úÖ Available' if MTCNN_AVAILABLE else '‚ùå Not Available'}")
    st.sidebar.write(f"Scikit-learn: {'‚úÖ Available' if SKLEARN_AVAILABLE else '‚ùå Not Available'}")
    
    # Main interface
    st.markdown('<h2 class="sub-header">üì∏ Upload Image for Analysis</h2>', 
                unsafe_allow_html=True)
    
    uploaded_file = st.file_uploader(
        "Choose an image file", 
        type=['jpg', 'jpeg', 'png', 'bmp'],
        help="Upload a clear image with a visible face for best results"
    )
    
    if uploaded_file is not None:
        # Display uploaded image
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.subheader("üì∑ Original Image")
            image = Image.open(uploaded_file)
            st.image(image, caption="Uploaded Image", use_column_width=True)
        
        with col2:
            st.subheader("üéØ Processing Status")
            status_container = st.empty()
            
            # Process image
            if st.button("üöÄ Analyze Image", type="primary"):
                start_time = time.time()
                
                # Face detection if enabled
                if use_face_detection and st.session_state.detector:
                    status_container.info("üîç Detecting face...")
                    face, face_message = extract_face_with_mtcnn(
                        np.array(image), st.session_state.detector
                    )
                    
                    if face is not None:
                        st.image(face, caption="Detected Face", use_column_width=True)
                        processing_image = face
                    else:
                        st.warning(f"‚ö†Ô∏è {face_message}")
                        processing_image = np.array(image)
                elif use_face_detection:
                    status_container.info("üîç Extracting face region...")
                    face, face_message = extract_face_simple(np.array(image))
                    if face is not None:
                        st.image(face, caption="Extracted Face Region", use_column_width=True)
                        processing_image = face
                    else:
                        processing_image = np.array(image)
                else:
                    processing_image = np.array(image)
                
                # Model predictions
                results = []
                predictions = []
                confidences = []
                
                status_container.info("ü§ñ Running model predictions...")
                
                # Selected models
                selected_models = []
                if use_mesonet:
                    selected_models.append(('mesonet', 'MesoNet (BCN+AGLU)', 1.2))
                if use_mobilevit:
                    selected_models.append(('mobilevit', 'MobileViT XXS', 1.1))
                if use_efficientnet:
                    selected_models.append(('efficientnet', 'EfficientNet B0', 1.0))
                if use_resnet:
                    selected_models.append(('resnet50', 'ResNet50', 0.9))
                if use_vit:
                    selected_models.append(('vit', 'Vision Transformer', 1.0))
                if use_densenet:
                    selected_models.append(('densenet', 'DenseNet121', 0.95))
                if use_inception:
                    selected_models.append(('inception', 'InceptionV3', 0.9))
                
                weights = []
                for model_key, model_name, weight in selected_models:
                    result, conf, msg = predict_with_model(
                        st.session_state.models.get(model_key), 
                        processing_image, 
                        model_name
                    )
                    if result:
                        results.append([model_name, result, f"{conf:.4f}", msg])
                        predictions.append(result)
                        confidences.append(conf)
                        weights.append(weight)
                
                # Ensemble prediction
                if len(predictions) > 1:
                    ensemble_result, ensemble_conf = ensemble_prediction(predictions, confidences, weights)
                    results.append(["Ensemble Voting", ensemble_result, f"{ensemble_conf:.4f}", "Weighted combination"])
                
                processing_time = time.time() - start_time
                status_container.success(f"‚úÖ Analysis completed in {processing_time:.2f} seconds")
                
                # Display results
                st.markdown('<h2 class="sub-header">üìä Detection Results</h2>', 
                           unsafe_allow_html=True)
                
                if results:
                    # Create results DataFrame
                    results_df = pd.DataFrame(results, columns=['Model', 'Prediction', 'Confidence', 'Status'])
                    
                    # Main result summary
                    fake_count = sum(1 for result in results if result[1] == 'FAKE')
                    real_count = len(results) - fake_count
                    
                    if fake_count > real_count:
                        final_prediction = "FAKE"
                        confidence_color = "#ffebee"
                        text_color = "#c62828"
                        result_emoji = "üö®"
                    else:
                        final_prediction = "REAL"
                        confidence_color = "#e8f5e8"
                        text_color = "#2e7d32"
                        result_emoji = "‚úÖ"
                    
                    # Display final result
                    st.markdown(f"""
                    <div style="background-color: {confidence_color}; color: {text_color}; 
                                padding: 2rem; border-radius: 15px; text-align: center; 
                                margin: 2rem 0; border: 2px solid {text_color};">
                        <h1>{result_emoji} FINAL PREDICTION: {final_prediction}</h1>
                        <h3>Consensus: {fake_count if final_prediction == 'FAKE' else real_count}/{len(results)} models agree</h3>
                    </div>
                    """, unsafe_allow_html=True)
                    
                    # Detailed results table
                    st.subheader("üìã Detailed Model Results")
                    
                    # Display results with color coding
                    for i, result in enumerate(results):
                        col1, col2, col3, col4 = st.columns([3, 2, 2, 3])
                        
                        with col1:
                            st.write(f"**{result[0]}**")
                        
                        with col2:
                            if result[1] == "FAKE":
                                st.markdown(f'<span style="color: red; font-weight: bold;">üö® {result[1]}</span>', 
                                          unsafe_allow_html=True)
                            else:
                                st.markdown(f'<span style="color: green; font-weight: bold;">‚úÖ {result[1]}</span>', 
                                          unsafe_allow_html=True)
                        
                        with col3:
                            st.write(f"**{result[2]}**")
                        
                        with col4:
                            st.write(result[3])
                    
                    # Interactive visualization
                    if show_detailed_analysis:
                        st.subheader("üìà Analysis Dashboard")
                        
                        # Convert confidence strings to floats for analysis
                        conf_values = [float(r[2]) for r in results]
                        
                        # Create visualization
                        fig = create_results_visualization(results_df)
                        st.pyplot(fig)
                        
                        # Statistical analysis
                        st.subheader("üìä Statistical Analysis")
                        
                        col1, col2, col3, col4 = st.columns(4)
                        
                        with col1:
                            avg_confidence = np.mean(conf_values)
                            st.metric("Average Confidence", f"{avg_confidence:.3f}")
                        
                        with col2:
                            std_confidence = np.std(conf_values)
                            st.metric("Confidence Std Dev", f"{std_confidence:.3f}")
                        
                        with col3:
                            agreement_rate = max(fake_count, real_count) / len(results)
                            st.metric("Model Agreement", f"{agreement_rate:.1%}")
                        
                        with col4:
                            st.metric("Processing Time", f"{processing_time:.2f}s")
                        
                        # Model performance insights
                        st.subheader("‚ö° Model Performance Insights")
                        
                        performance_data = []
                        for result in results:
                            model_name = result[0]
                            prediction = result[1]
                            confidence = float(result[2])
                            
                            # Calculate performance score
                            if prediction == final_prediction:
                                performance_score = confidence * 100
                            else:
                                performance_score = (1 - confidence) * 50
                            
                            performance_data.append({
                                'Model': model_name,
                                'Performance Score': performance_score,
                                'Agrees with Consensus': prediction == final_prediction,
                                'Confidence': confidence
                            })
                        
                        perf_df = pd.DataFrame(performance_data)
                        
                        # Performance chart
                        fig, ax = plt.subplots(figsize=(12, 6))
                        colors = ['green' if agrees else 'red' for agrees in perf_df['Agrees with Consensus']]
                        bars = ax.bar(perf_df['Model'], perf_df['Performance Score'], color=colors, alpha=0.7)
                        ax.set_title('Model Performance Comparison')
                        ax.set_ylabel('Performance Score')
                        ax.tick_params(axis='x', rotation=45)
                        
                        # Add value labels on bars
                        for bar, score in zip(bars, perf_df['Performance Score']):
                            height = bar.get_height()
                            ax.text(bar.get_x() + bar.get_width()/2., height + 1,
                                   f'{score:.1f}', ha='center', va='bottom')
                        
                        plt.tight_layout()
                        st.pyplot(fig)
                        
                        # Detailed analysis
                        st.subheader("üîç Detailed Analysis")
                        
                        st.markdown(f"""
                        **Analysis Summary:**
                        - **Total Models Used:** {len(results)}
                        - **Consensus Strength:** {max(fake_count, real_count) / len(results):.1%}
                        - **Average Confidence:** {np.mean(conf_values):.3f}
                        - **Confidence Range:** {np.min(conf_values):.3f} - {np.max(conf_values):.3f}
                        - **Processing Time:** {processing_time:.2f} seconds
                        
                        **Recommendations:**
                        """)
                        
                        if agreement_rate >= 0.8:
                            st.success("‚úÖ **High Confidence Result** - Strong agreement among models")
                        elif agreement_rate >= 0.6:
                            st.warning("‚ö†Ô∏è **Moderate Confidence** - Reasonable agreement among models")
                        else:
                            st.error("‚ùå **Low Confidence** - Models disagree significantly. Consider additional analysis.")
                        
                        if std_confidence > 0.2:
                            st.info("üí° **High Variance** in confidence scores suggests the image may be challenging to classify")
                        
                        if avg_confidence < 0.7:
                            st.info("üí° **Lower Average Confidence** - Consider using additional models or higher quality images")
                
                else:
                    st.error("‚ùå No valid predictions were generated. Please check your model selection and try again.")
    
    # Information sidebar
    with st.sidebar:
        st.markdown("---")
        st.subheader("üìö Model Information")
        
        with st.expander("About the Models"):
            st.write("""
            **MesoNet (BCN + AGLU)**
            - Specialized for deepfake detection
            - Enhanced with Batch Channel Normalization
            - Uses Adaptive Gaussian Linear Unit activation
            - Lightweight and fast inference
            
            **MobileViT XXS**
            - Mobile-optimized Vision Transformer
            - Combines CNN and Transformer strengths
            - Efficient for mobile deployment
            
            **EfficientNet B0**
            - Efficient convolutional architecture
            - Balanced accuracy and efficiency
            - Pre-trained on ImageNet
            
            **Additional Models**
            - ResNet50, DenseNet121, InceptionV3
            - Vision Transformer for comparison
            - Ensemble voting for final decision
            """)
        
        st.markdown("---")
        st.subheader("‚ö†Ô∏è Important Notes")
        st.warning("""
        - Ensure good image quality for best results
        - Face detection improves accuracy significantly
        - Multiple models provide more reliable predictions
        - This is a demonstration system
        - Results may vary with different images
        """)
        
        st.markdown("---")
        st.subheader("üîß Technical Info")
        st.info(f"""
        - Models loaded: {len(st.session_state.models) if st.session_state.models_loaded else 0}
        - TensorFlow: {'Available' if TF_AVAILABLE else 'Demo Mode'}
        - Face Detection: {'MTCNN' if MTCNN_AVAILABLE else 'Basic'}
        """)

if __name__ == "__main__":
    main()